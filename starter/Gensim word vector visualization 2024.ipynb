{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gensim word vector visualization of various word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get the interactive Tools for Matplotlib\n",
    "# %matplotlib notebook\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import gensim.downloader as api\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For looking at word vectors, I'll use Gensim. Gensim isn't really a deep learning package. It's a package for word and text similarity modeling, which started with (LDA-style) topic models and grew into SVD and neural word representations. But its efficient and scalable, and quite widely used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll use homegrown Stanford offering of GloVe word vectors. Gensim provides a library of several sets of word vectors that you can easily load. You can find out more about GloVe on [the Glove page](https://nlp.stanford.edu/projects/glove/). I use the 100d vectors below as a balance between speed and smallness vs. quality. If you try out the 50d vectors, they basically work for similarity but clearly aren't as good for analogy problems. If you load the 300d vectors, you'll wait longer, but they're even better than the 100d vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'gensim.models.keyedvectors.KeyedVectors'>\n"
     ]
    }
   ],
   "source": [
    "model = api.load(\"glove-wiki-gigaword-100\")\n",
    "print(type(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.66146  ,  0.94335  , -0.72214  ,  0.17403  , -0.42524  ,\n",
       "        0.36303  ,  1.0135   , -0.14802  ,  0.25817  , -0.20326  ,\n",
       "       -0.64338  ,  0.16632  ,  0.61518  ,  1.397    , -0.094506 ,\n",
       "        0.0041843, -0.18976  , -0.55421  , -0.39371  , -0.22501  ,\n",
       "       -0.34643  ,  0.32076  ,  0.34395  , -0.7034   ,  0.23932  ,\n",
       "        0.69951  , -0.16461  , -0.31819  , -0.34034  , -0.44906  ,\n",
       "       -0.069667 ,  0.35348  ,  0.17498  , -0.95057  , -0.2209   ,\n",
       "        1.0647   ,  0.23231  ,  0.32569  ,  0.47662  , -1.1206   ,\n",
       "        0.28168  , -0.75172  , -0.54654  , -0.66337  ,  0.34804  ,\n",
       "       -0.69058  , -0.77092  , -0.40167  , -0.069351 , -0.049238 ,\n",
       "       -0.39351  ,  0.16735  , -0.14512  ,  1.0083   , -1.0608   ,\n",
       "       -0.87314  , -0.29339  ,  0.68278  ,  0.61634  , -0.088844 ,\n",
       "        0.88094  ,  0.099809 , -0.27161  , -0.58026  ,  0.50364  ,\n",
       "       -0.93814  ,  0.67576  , -0.43124  , -0.10517  , -1.2404   ,\n",
       "       -0.74353  ,  0.28637  ,  0.29012  ,  0.89377  ,  0.67406  ,\n",
       "        0.86422  , -0.30693  , -0.14718  ,  0.078353 ,  0.74013  ,\n",
       "        0.32658  , -0.052579 , -1.1665   ,  0.87079  , -0.69402  ,\n",
       "       -0.75977  , -0.37164  , -0.11887  ,  0.18551  ,  0.041883 ,\n",
       "        0.59352  ,  0.30519  , -0.54819  , -0.29424  , -1.4912   ,\n",
       "       -1.6548   ,  0.98982  ,  0.27325  ,  1.009    ,  0.94544  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['bread']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.25144  ,  0.52157  , -0.75452  ,  0.28039  , -0.31388  ,\n",
       "        0.274    ,  1.1971   , -0.10519  ,  0.82544  , -0.33398  ,\n",
       "       -0.21417  ,  0.22216  ,  0.14982  ,  0.47384  ,  0.41984  ,\n",
       "        0.69397  , -0.25999  , -0.44414  ,  0.58296  , -0.30851  ,\n",
       "       -0.076455 ,  0.33468  ,  0.28055  , -0.99012  ,  0.30349  ,\n",
       "        0.39128  ,  0.031526 , -0.095395 , -0.004745 , -0.81347  ,\n",
       "        0.27869  , -0.1812   ,  0.14632  , -0.42186  ,  0.13857  ,\n",
       "        1.139    ,  0.14925  , -0.051459 ,  0.37875  , -0.2613   ,\n",
       "        0.011081 , -0.28881  , -0.38662  , -0.3135   , -0.1954   ,\n",
       "        0.19248  , -0.52995  , -0.40674  , -0.25159  ,  0.06272  ,\n",
       "       -0.32724  ,  0.28374  , -0.2155   , -0.061832 , -0.50134  ,\n",
       "        0.0093959,  0.30715  ,  0.3873   , -0.74554  , -0.45947  ,\n",
       "        0.40032  , -0.1378   , -0.26968  , -0.3946   , -0.64876  ,\n",
       "       -0.47149  , -0.085536 ,  0.092795 , -0.034018 , -0.61906  ,\n",
       "        0.19123  ,  0.20563  ,  0.29056  , -0.010908 ,  0.15313  ,\n",
       "        0.33144  ,  0.33806  ,  0.061708 ,  0.20785  ,  0.65348  ,\n",
       "       -0.053222 ,  0.18589  ,  0.32647  , -0.11923  ,  0.42008  ,\n",
       "       -0.26931  ,  0.025489 ,  0.0036535,  0.1327   , -0.22763  ,\n",
       "        0.07564  ,  0.55773  ,  0.2978   ,  0.28144  ,  0.19775  ,\n",
       "       -0.23582  ,  0.65303  ,  0.089897 ,  0.35844  ,  0.14304  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['croissant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('canada', 0.6544384360313416),\n",
       " ('america', 0.645224392414093),\n",
       " ('u.s.a.', 0.6184033155441284),\n",
       " ('united', 0.6017189621925354),\n",
       " ('states', 0.5970699191093445),\n",
       " ('australia', 0.5838716626167297),\n",
       " ('world', 0.5590084791183472),\n",
       " ('2010', 0.5580702424049377),\n",
       " ('2012', 0.5504006743431091),\n",
       " ('davis', 0.5464468002319336)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('usa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('coconut', 0.7097253203392029),\n",
       " ('mango', 0.7054824829101562),\n",
       " ('bananas', 0.6887733936309814),\n",
       " ('potato', 0.6629636883735657),\n",
       " ('pineapple', 0.6534532308578491),\n",
       " ('fruit', 0.6519854664802551),\n",
       " ('peanut', 0.6420576572418213),\n",
       " ('pecan', 0.6349173784255981),\n",
       " ('cashew', 0.6294420957565308),\n",
       " ('papaya', 0.6246591210365295)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('banana')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('croissants', 0.6829844117164612),\n",
       " ('brioche', 0.6283303499221802),\n",
       " ('baguette', 0.5968102812767029),\n",
       " ('focaccia', 0.5876684784889221),\n",
       " ('pudding', 0.5803956389427185),\n",
       " ('souffle', 0.5614769458770752),\n",
       " ('baguettes', 0.5558240413665771),\n",
       " ('tortilla', 0.5449503064155579),\n",
       " ('pastries', 0.5427731275558472),\n",
       " ('calzone', 0.5374532341957092)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('croissant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('shunichi', 0.49618107080459595),\n",
       " ('ieronymos', 0.4736502468585968),\n",
       " ('pengrowth', 0.4668096601963043),\n",
       " ('hÃ¶ss', 0.4636845886707306),\n",
       " ('damaskinos', 0.4617849290370941),\n",
       " ('yadin', 0.4617374837398529),\n",
       " ('hundertwasser', 0.458895742893219),\n",
       " ('ncpa', 0.4577338993549347),\n",
       " ('maccormac', 0.4566109776496887),\n",
       " ('rothfeld', 0.4523947238922119)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(negative='banana')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queen: 0.7699\n"
     ]
    }
   ],
   "source": [
    "result = model.most_similar(positive=['woman', 'king'], negative=['man'])\n",
    "print(\"{}: {:.4f}\".format(*result[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1 : x2 :: y1 :: returned\n",
    "def analogy(x1, x2, y1):\n",
    "    result = model.most_similar(positive=[y1, x2], negative=[x1])\n",
    "    return result[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analogy king-queen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'queen'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy('man', 'king', 'woman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'champagne'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy('australia', 'beer', 'france')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'photographing'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy('pencil', 'sketching', 'camera')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nixon'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy('obama', 'clinton', 'reagan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'longest'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy('tall', 'tallest', 'long')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cereal\n"
     ]
    }
   ],
   "source": [
    "print(model.doesnt_match(\"breakfast cereal dinner lunch\".split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_pca_scatterplot(model, words=None, sample=0):\n",
    "    if words == None:\n",
    "        if sample > 0:\n",
    "            words = np.random.choice(list(model.vocab.keys()), sample)\n",
    "        else:\n",
    "            words = [ word for word in model.vocab ]\n",
    "        \n",
    "    word_vectors = np.array([model[w] for w in words])\n",
    "\n",
    "    twodim = PCA().fit_transform(word_vectors)[:,:2]\n",
    "    \n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.scatter(twodim[:,0], twodim[:,1], edgecolors='k', c='r')\n",
    "    for word, (x,y) in zip(words, twodim):\n",
    "        plt.annotate(word, (x, y), xytext=(x+0.05, y+0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display_pca_scatterplot(model, \n",
    "    ['coffee', 'tea', 'beer', 'wine', 'brandy', 'rum', 'champagne', 'water',\n",
    "        'spaghetti', 'borscht', 'hamburger', 'pizza', 'falafel', 'sushi', 'meatballs',\n",
    "        'dog', 'horse', 'cat', 'monkey', 'parrot', 'koala', 'lizard',\n",
    "        'frog', 'toad', 'monkey', 'ape', 'kangaroo', 'wombat', 'wolf',\n",
    "        'france', 'germany', 'hungary', 'luxembourg', 'australia', 'china', 'iran',\n",
    "        'homework', 'assignment', 'problem', 'exam', 'test', 'class',\n",
    "        'school', 'college', 'university', 'institute'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
